import pandas as pd
import re
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException
from time import sleep
import warnings

warnings.filterwarnings("ignore")

city =input("Enter your city Name:")
query =input("Enter your query Name:")


driver = webdriver.Chrome(r"C:\Users\rohit\Downloads\chromedriverwin32\chromedriver.exe")
url = f'https://www.google.com/search?rlz=1C1CHBF_enIN958IN958&tbs=lf:1,lf_ui:10&tbm=lcl&sxsrf=APwXEddUTd0fg4wRXdUC4gcAep7GyrixIw:1686030109380&q={query}+in+{city}&rflfq=1&num=10&sa=X&ved=2ahUKEwjr5P_N963_AhWaFIgKHTVwArQQjGp6BAgREAE&biw=1536&bih=714&dpr=1.25'
driver.get(url)
sleep(2)

data_list = []
page_number = 0

while True:
    elements = driver.find_elements(By.CLASS_NAME, 'VkpGBb')

    for element in elements:
        try:
            element.click()
            sleep(2)

            address_elements = driver.find_elements(By.CLASS_NAME, 'Z1hOCe')
            address = address_elements[0].text if len(address_elements) > 0 else ''

            phone_elements = driver.find_elements(By.CLASS_NAME, 'Z1hOCe')
            phone_number = phone_elements[1].text if len(phone_elements) > 1 else ''

            name_elements = driver.find_elements(By.CLASS_NAME, 'wDYxhc')
            name = name_elements[0].text if len(name_elements) > 0 else ''

            rating_elements = driver.find_elements(By.CLASS_NAME, 'TLYLSe')
            rating = rating_elements[0].text if len(rating_elements) > 0 else ''

            href_element = driver.find_element(By.CLASS_NAME, 'dHS6jb')
            href_link = href_element.get_attribute('href')

            # Append the data to the DataFrame
            df = pd.DataFrame([[address, phone_number, name, rating, href_link]], columns=['Address', 'Phone Number', 'Name', 'Rating', 'HREF'])
            data_list.append(df)

        except (StaleElementReferenceException, NoSuchElementException):
            pass

    # Print the page number
    print("Page:", page_number)

    # Navigate to the next page of results if available
    try:
        next_button = driver.find_element(By.XPATH, '//*[@id="pnnext"]/span[2]')
        next_button.click()
        page_number += 1
        sleep(2)
    except NoSuchElementException:
        break

driver.quit()

# Concatenate all the data frames in the list
df = pd.concat(data_list, ignore_index=True)

# Save the data to an Excel file with the name of the input city and query
file_name = f"{city}_{query}.xlsx"
df.to_excel(file_name, index=False)

print("Data saved to", file_name)
